{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WDd_Y_IxAsyE",
        "outputId": "75268ca7-baf8-467f-894e-ba0d56022234"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the URL to crawl: https://bwapp.hakhub.net/login.php\n",
            "Enter the number of levels to crawl: 2\n",
            "[WARNING] Possible RFI vulnerability in: https://bwapp.hakhub.net/login.php\n",
            "No SQL injection vulnerabilities detected\n",
            "Could not detect open ports on host: bwapp.hakhub.net\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "import re\n",
        "import socket\n",
        "import nmap\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "def crawl_website(url, n):\n",
        "    visited = set()\n",
        "    to_visit = [url]\n",
        "    level = 0\n",
        "\n",
        "    while to_visit and level <= n:\n",
        "        current_url = to_visit.pop(0)\n",
        "        visited.add(current_url)\n",
        "        try:\n",
        "            response = requests.get(current_url)\n",
        "            soup = BeautifulSoup(response.text, \"html.parser\")\n",
        "            links = [link.get(\"href\") for link in soup.find_all(\"a\")]\n",
        "            for link in links:\n",
        "                if link not in visited and link not in to_visit:\n",
        "                    to_visit.append(link)\n",
        "        except:\n",
        "            pass\n",
        "        level += 1\n",
        "    return visited\n",
        "\n",
        "\n",
        "def detect_sql_injection(url):\n",
        "    payloads = [\n",
        "        \"'\",\n",
        "        \"';\",\n",
        "        '\"',\n",
        "        '\";',\n",
        "        \"or 1=1--\",\n",
        "        \"or 1=1#\",\n",
        "        \"or 1=1/*\",\n",
        "        \"admin'--\",\n",
        "        \"admin'#\",\n",
        "        \"admin'/*\",\n",
        "        \"admin' or '1'='1\",\n",
        "        \"admin' or 1=1--\",\n",
        "        \"admin' or 1=1#\",\n",
        "        \"admin' or 1=1/*\",\n",
        "    ]\n",
        "    for payload in payloads:\n",
        "        injection_url = url + payload\n",
        "        try:\n",
        "            response = requests.get(injection_url)\n",
        "            if \"error\" in response.text.lower() or \"syntax\" in response.text.lower():\n",
        "                return \"SQL injection vulnerability detected with payload: \" + payload\n",
        "        except:\n",
        "            pass\n",
        "    return \"No SQL injection vulnerabilities detected\"\n",
        "\n",
        "\n",
        "def detect_open_ports(url):\n",
        "    host = url.split(\"//\")[1].split(\"/\")[0]\n",
        "    try:\n",
        "        ip = socket.gethostbyname(host)\n",
        "        nm = nmap.PortScanner()\n",
        "        nm.scan(ip, arguments=\"-T4 -F\")\n",
        "        open_ports = [\n",
        "            str(port) + \"/\" + nm[ip][\"tcp\"][port][\"name\"]\n",
        "            for port in nm[ip].all_tcp()\n",
        "            if nm[ip][\"tcp\"][port][\"state\"] == \"open\"\n",
        "        ]\n",
        "        if open_ports:\n",
        "            return \"Open ports detected on host: \" + host + \"\\n\" + \"\\n\".join(open_ports)\n",
        "        else:\n",
        "            return \"No open ports detected on host: \" + host\n",
        "    except:\n",
        "        return \"Could not detect open ports on host: \" + host\n",
        "\n",
        "\n",
        "def detect_xss(urls):\n",
        "    for url in urls:\n",
        "        try:\n",
        "            response = requests.get(url)\n",
        "            if \"<script>\" in response.text.lower():\n",
        "                print(f\"[WARNING] Possible XSS vulnerability in: {url}\")\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "\n",
        "def detect_remote_file_inclusion(urls):\n",
        "    for url in urls:\n",
        "        try:\n",
        "            response = requests.get(url)\n",
        "            if (\n",
        "                \"http://\" in response.text.lower()\n",
        "                or \"https://\" in response.text.lower()\n",
        "            ):\n",
        "                print(f\"[WARNING] Possible RFI vulnerability in: {url}\")\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "\n",
        "def detect_regular_expression_dos(urls):\n",
        "    for url in urls:\n",
        "        try:\n",
        "            response = requests.get(url)\n",
        "            if re.search(r\"(a+){10,}\", response.text):\n",
        "                print(\n",
        "                    f\"[WARNING] Possible regular expression DoS vulnerability in: {url}\"\n",
        "                )\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "\n",
        "url = input(\"Enter the URL to crawl: \")\n",
        "n = int(input(\"Enter the number of levels to crawl: \"))\n",
        "\n",
        "visited_urls = crawl_website(url, n)\n",
        "detect_xss(visited_urls)\n",
        "detect_remote_file_inclusion(visited_urls)\n",
        "detect_regular_expression_dos(visited_urls)\n",
        "print(detect_sql_injection(url))\n",
        "print(detect_open_ports(url))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "S024IvPLmcI9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}